{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2b0f9b",
   "metadata": {},
   "source": [
    "### Load Formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dfc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8f4ec",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15660d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d77737",
   "metadata": {},
   "source": [
    "### Generate some fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a360ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_true = 0.75\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "for size in [10 ** i for i in range(1, 7)]:\n",
    "    x = stats.bernoulli.rvs(p=p_true, size=size, random_state=42)\n",
    "    pdf = pdf.append(pd.DataFrame({\"size\": size, \"x\": x}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc9fb2",
   "metadata": {},
   "source": [
    "### Model with whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pdf.x.values[0:100]\n",
    "\n",
    "with pm.Model() as model:\n",
    "    p = pm.Beta(\"p\", alpha=1, beta=1)\n",
    "    obs = pm.Bernoulli(\"obs\", p=p, observed=x)\n",
    "\n",
    "    trace = pm.sample(1_000, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_bernoulli_model(pdf: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    x = pdf.x.values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        p = pm.Beta(\"p\", alpha=1, beta=1)\n",
    "        obs = pm.Bernoulli(\"obs\", p=p, observed=x)\n",
    "        trace = pm.sample(1_000, return_inferencedata=False)\n",
    "\n",
    "    t1 = datetime.now()\n",
    "\n",
    "    p_hat = trace[\"p\"].mean()\n",
    "    hdi = pm.hdi(trace[\"p\"], hdi_prob=0.94)\n",
    "    sample_time = trace.report.t_sampling\n",
    "    deltat = t1 - t0\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"p_hat\": p_hat,\n",
    "            \"hdi_3%\": hdi[0],\n",
    "            \"hdi_97%\": hdi[1],\n",
    "            \"runtime\": deltat,\n",
    "            \"sample_time\": sample_time,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9458966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pdf.groupby(\"size\").apply(pandas_bernoulli_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e27aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bernoulli_loglike(p, weight, value):\n",
    "    loglike = weight * pm.Bernoulli.dist(p=p).logp(value)\n",
    "    return loglike\n",
    "\n",
    "\n",
    "def pandas_bernoulli_model_agg(pdf: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    pdf_agg = pdf.assign(freq=1).groupby([\"x\"]).agg({\"freq\": \"count\"}).reset_index()\n",
    "    weights = pdf_agg.freq.values\n",
    "    values = pdf_agg.x.values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        p = pm.Beta(\"p\", alpha=1, beta=1)\n",
    "        obs = pm.Potential(\n",
    "            \"obs\", weighted_bernoulli_loglike(p=p, weight=weights, value=values)\n",
    "        )\n",
    "        trace = pm.sample(1_000, return_inferencedata=False)\n",
    "    t1 = datetime.now()\n",
    "\n",
    "    p_hat = trace[\"p\"].mean()\n",
    "    hdi = pm.hdi(trace[\"p\"], hdi_prob=0.94)\n",
    "    sample_time = trace.report.t_sampling\n",
    "    deltat = t1 - t0\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"p_hat\": p_hat,\n",
    "            \"hdi_3%\": hdi[0],\n",
    "            \"hdi_97%\": hdi[1],\n",
    "            \"runtime\": deltat,\n",
    "            \"sample_time\": sample_time,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861916f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_agg = pdf.groupby(\"size\").apply(pandas_bernoulli_model_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f72c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agg.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa93bc5",
   "metadata": {},
   "source": [
    "### Poisson Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = 100\n",
    "pdf_poisson = pd.DataFrame()\n",
    "\n",
    "for size in [10 ** j for j in range(1, 7)]:\n",
    "    x = stats.poisson.rvs(mu_true, size=size, random_state=42)\n",
    "    pdf_poisson = pdf_poisson.append(pd.DataFrame({\"size\": size, \"x\": x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c14564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_poisson_model(pdf: pd.DataFrame):\n",
    "\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    x = pdf[\"x\"].values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        mu = pm.Gamma(\"mu\", alpha=1, beta=1)\n",
    "        obs = pm.Poisson(\"obs\", mu=mu, observed=x)\n",
    "        trace = pm.sample(1_000, return_inferencedata=False)\n",
    "\n",
    "    t1 = datetime.now()\n",
    "    deltat = t1 - t0\n",
    "    mu_hat = trace[\"mu\"].mean()\n",
    "    sample_time = trace.report.t_sampling\n",
    "    hdi = pm.hdi(trace[\"mu\"], hdi_prob=0.94)\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"mu_hat\": mu_hat,\n",
    "            \"hdi_3%\": hdi[0],\n",
    "            \"hdi_97%\": hdi[1],\n",
    "            \"runtime\": deltat,\n",
    "            \"sample_time\": sample_time,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5c50e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poisson_results = pdf_poisson.groupby([\"size\"]).apply(pandas_poisson_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_results.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_likelihood(weight, value, mu):\n",
    "    return weight * pm.Poisson.dist(mu=mu).logp(value)\n",
    "\n",
    "\n",
    "def pandas_poisson_model_agg(pdf: pd.DataFrame):\n",
    "\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    pdf_agg = pdf.assign(freq=1).groupby([\"x\"]).agg({\"freq\": \"count\"}).reset_index()\n",
    "\n",
    "    values = pdf_agg[\"x\"].values\n",
    "    weights = pdf_agg[\"freq\"].values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        mu = pm.Gamma(\"mu\", alpha=1, beta=1)\n",
    "        obs = pm.Potential(\n",
    "            \"obs\", poisson_likelihood(weight=weights, value=values, mu=mu)\n",
    "        )\n",
    "        trace = pm.sample(1_000, return_inferencedata=False)\n",
    "\n",
    "    t1 = datetime.now()\n",
    "    deltat = t1 - t0\n",
    "    mu_hat = trace[\"mu\"].mean()\n",
    "    sample_time = trace.report.t_sampling\n",
    "    hdi = pm.hdi(trace[\"mu\"], hdi_prob=0.94)\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"mu_hat\": mu_hat,\n",
    "            \"hdi_3%\": hdi[0],\n",
    "            \"hdi_97%\": hdi[1],\n",
    "            \"runtime\": deltat,\n",
    "            \"sample_time\": sample_time,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cd7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poisson_results_agg = pdf_poisson.groupby([\"size\"]).apply(pandas_poisson_model_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c711385",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_results_agg.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1359495",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = (2.5,)\n",
    "sigma_true = 5\n",
    "\n",
    "pdf_normal = pd.DataFrame()\n",
    "\n",
    "for size in [10 ** i for i in range(1, 7)]:\n",
    "\n",
    "    x = stats.norm.rvs(loc=mu_true, scale=sigma_true, size=size, random_state=42)\n",
    "\n",
    "    pdf_normal = pdf_normal.append(pd.DataFrame({\"size\": size, \"x\": x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_normal_model(pdf: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    x = pdf.x.values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        mu = pm.Normal(\"mu\", mu=0, sigma=1)\n",
    "        sigma = pm.HalfCauchy(\"sigma\", beta=5)\n",
    "\n",
    "        obs = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=x)\n",
    "\n",
    "        trace = pm.sample(1_000)\n",
    "\n",
    "    t1 = datetime.now()\n",
    "    deltat = t1 - t0\n",
    "\n",
    "    mu_hat = trace[\"mu\"].mean()\n",
    "    hdi_mu = pm.hdi(trace[\"mu\"], hdi_prob=0.94)\n",
    "\n",
    "    sigma_hat = trace[\"sigma\"].mean()\n",
    "    hdi_sigma = pm.hdi(trace[\"sigma\"], hdi_prob=0.94)\n",
    "\n",
    "    sample_time = trace.report.t_sampling\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"mu_hat\": mu_hat,\n",
    "            \"hdi_mu_3%\": hdi_mu[0],\n",
    "            \"hdi_mu_97%\": hdi_mu[1],\n",
    "            \"sigma_hat\": sigma_hat,\n",
    "            \"hdi_sigma_3%\": hdi_sigma[0],\n",
    "            \"hdi_sigma_97%\": hdi_sigma[1],\n",
    "            \"runtime\": deltat,\n",
    "            \"sample_time\": sample_time,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a11f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_normal = pdf_normal.groupby(\"size\").apply(pandas_normal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53606b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_normal.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a62d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_likelihood(weight, value, mu, sigma):\n",
    "    return weight * pm.Normal.dist(mu=mu, sigma=sigma).logp(value)\n",
    "\n",
    "\n",
    "def pandas_normal_model_agg(pdf: pd.DataFrame, bins: int) -> pd.Series:\n",
    "\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    pdf_model = (\n",
    "        pdf.assign(bucket=lambda x: pd.cut(x[\"x\"], bins=100), freq=1)\n",
    "        .groupby(\"bucket\")\n",
    "        .agg({\"x\": \"mean\", \"freq\": \"count\"})\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    values = pdf_model[\"x\"].values\n",
    "    weights = pdf_model[\"freq\"].values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        mu = pm.Normal(\"mu\", mu=0, sigma=1)\n",
    "        sigma = pm.HalfCauchy(\"sigma\", beta=5)\n",
    "\n",
    "        obs = pm.Potential(\n",
    "            \"obs\", normal_likelihood(weight=weights, value=values, mu=mu, sigma=sigma)\n",
    "        )\n",
    "\n",
    "        trace = pm.sample(1_000)\n",
    "\n",
    "    t1 = datetime.now()\n",
    "    deltat = t1 - t0\n",
    "\n",
    "    mu_hat = trace[\"mu\"].mean()\n",
    "    hdi_mu = pm.hdi(trace[\"mu\"], hdi_prob=0.94)\n",
    "\n",
    "    sigma_hat = trace[\"sigma\"].mean()\n",
    "    hdi_sigma = pm.hdi(trace[\"sigma\"], hdi_prob=0.94)\n",
    "\n",
    "    sample_time = trace.report.t_sampling\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"mu_hat\": mu_hat,\n",
    "            \"hdi_mu_3%\": hdi_mu[0],\n",
    "            \"hdi_mu_97%\": hdi_mu[1],\n",
    "            \"sigma_hat\": sigma_hat,\n",
    "            \"hdi_sigma_3%\": hdi_sigma[0],\n",
    "            \"hdi_sigma_97%\": hdi_sigma[1],\n",
    "            \"runtime\": deltat,\n",
    "            \"sample_time\": sample_time,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60e376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_normal_agg = pdf_normal.groupby(\"size\").apply(\n",
    "    lambda x: pandas_normal_model_agg(x, bins=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83f3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_normal_agg.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116d42a",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import chart_studio\n",
    "\n",
    "username = \"your_username\"\n",
    "api_key = \"your_api\"\n",
    "chart_studio.tools.set_credentials_file(username=username, api_key=api_key)\n",
    "\n",
    "import chart_studio.plotly as py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agg.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ec2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_results.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_results_agg.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82400b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "pdf_aux = results.reset_index()\n",
    "x = pdf_aux[\"size\"].values\n",
    "y = pdf_aux[\"p_hat\"].values\n",
    "ylower = pdf_aux[\"hdi_3%\"].values\n",
    "yupper = pdf_aux[\"hdi_97%\"].values\n",
    "y2 = pdf_aux[\"sample_time\"].values\n",
    "\n",
    "fig = fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=np.append(x, x[::-1]),  # x, then x reversed\n",
    "            y=np.append(yupper, ylower[::-1]),  # upper, then lower reversed\n",
    "            fill=\"toself\",\n",
    "            name=\"HDI Bands (94%)\",\n",
    "            mode=\"lines\",\n",
    "        ),\n",
    "        go.Scatter(x=x, y=y, name=\"Estimate\"),\n",
    "    ]\n",
    ").add_trace(go.Scatter(x=x, y=y2, name=\"Sampling Time\"), secondary_y=True)\n",
    "\n",
    "pdf_aux = results_agg.reset_index()\n",
    "x = pdf_aux[\"size\"].values\n",
    "y = pdf_aux[\"p_hat\"].values\n",
    "ylower = pdf_aux[\"hdi_3%\"].values\n",
    "yupper = pdf_aux[\"hdi_97%\"].values\n",
    "y2 = pdf_aux[\"sample_time\"].values\n",
    "\n",
    "fig = fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=np.append(x, x[::-1]),  # x, then x reversed\n",
    "            y=np.append(yupper, ylower[::-1]),  # upper, then lower reversed\n",
    "            fill=\"toself\",\n",
    "            name=\"HDI Bands (94%) (Agg.)\",\n",
    "            mode=\"lines\",\n",
    "        ),\n",
    "        go.Scatter(x=x, y=y, name=\"Estimate (Agg.)\"),\n",
    "    ]\n",
    ").add_trace(go.Scatter(x=x, y=y2, name=\"Sampling Time (Agg.)\"), secondary_y=True)\n",
    "\n",
    "fig = (\n",
    "    fig.update_xaxes(type=\"log\", title=\"Sample Size (log10 scale)\")\n",
    "    .update_yaxes(secondary_y=False, title=\"Estimate\")\n",
    "    .update_yaxes(title=\"Fitting Time\", secondary_y=True)\n",
    "    .update_layout(title=\"Bernoulli Model vs Agg. Bernoulli Model\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ebe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "py.plot(fig, filename=\"medium-scaling-byi-bernoulli\", auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78633d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[pdf[\"size\"] == 1_000].assign(weight=1).groupby(\"x\").agg(\n",
    "    {\"weight\": \"count\"}\n",
    ").reset_index().rename(columns={\"x\": \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_normal.drop(columns=[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2985580",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    specs=[[{}, {}], [{\"colspan\": 2}, None]],\n",
    "    subplot_titles=(\n",
    "        \"Mean Estimates\",\n",
    "        \"Standard Deviation Estimates\",\n",
    "        \"Sampling Time\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "pdf_aux = results_normal.reset_index()\n",
    "x = pdf_aux[\"size\"].values\n",
    "mu = pdf_aux[\"mu_hat\"].values\n",
    "mu_up = pdf_aux[\"hdi_mu_97%\"].values\n",
    "mu_lo = pdf_aux[\"hdi_mu_3%\"].values\n",
    "sigma = pdf_aux[\"sigma_hat\"].values\n",
    "sigma_up = pdf_aux[\"hdi_sigma_97%\"].values\n",
    "sigma_lo = pdf_aux[\"hdi_sigma_3%\"].values\n",
    "st = pdf_aux[\"sample_time\"].values\n",
    "\n",
    "pdf_aux = results_normal_agg.reset_index()\n",
    "mu_agg = pdf_aux[\"mu_hat\"].values\n",
    "mu_agg_up = pdf_aux[\"hdi_mu_97%\"].values\n",
    "mu_agg_lo = pdf_aux[\"hdi_mu_3%\"].values\n",
    "sigma_agg = pdf_aux[\"sigma_hat\"].values\n",
    "sigma_agg_up = pdf_aux[\"hdi_sigma_97%\"].values\n",
    "sigma_agg_lo = pdf_aux[\"hdi_sigma_3%\"].values\n",
    "st_agg = pdf_aux[\"sample_time\"].values\n",
    "\n",
    "fig = fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=np.append(x, x[::-1]),  # x, then x reversed\n",
    "            y=np.append(mu_up, mu_lo[::-1]),  # upper, then lower reversed\n",
    "            fill=\"toself\",\n",
    "            name=\"Mean HDI Bands (94%)\",\n",
    "            mode=\"lines\",\n",
    "        ),\n",
    "        go.Scatter(x=x, y=mu, name=\"Mean Estimate\"),\n",
    "        go.Scatter(\n",
    "            x=np.append(x, x[::-1]),  # x, then x reversed\n",
    "            y=np.append(mu_agg_up, mu_agg_lo[::-1]),  # upper, then lower reversed\n",
    "            fill=\"toself\",\n",
    "            name=\"Mean HDI Bands (94%) (Agg.)\",\n",
    "            mode=\"lines\",\n",
    "        ),\n",
    "        go.Scatter(x=x, y=mu_agg, name=\"Mean Estimate (Agg.)\"),\n",
    "        go.Scatter(\n",
    "            x=np.append(x, x[::-1]),  # x, then x reversed\n",
    "            y=np.append(sigma_up, sigma_lo[::-1]),  # upper, then lower reversed\n",
    "            fill=\"toself\",\n",
    "            name=\"Std. HDI Bands (94%)\",\n",
    "            mode=\"lines\",\n",
    "        ),\n",
    "        go.Scatter(x=x, y=sigma, name=\"Std. Estimate\"),\n",
    "        go.Scatter(\n",
    "            x=np.append(x, x[::-1]),  # x, then x reversed\n",
    "            y=np.append(sigma_agg_up, sigma_agg_lo[::-1]),  # upper, then lower reversed\n",
    "            fill=\"toself\",\n",
    "            name=\"Std. HDI Bands (94%) (Agg.)\",\n",
    "            mode=\"lines\",\n",
    "        ),\n",
    "        go.Scatter(x=x, y=sigma_agg, name=\"Std. Estimate (Agg.)\"),\n",
    "        go.Scatter(x=x, y=st, name=\"Train Time\"),\n",
    "        go.Scatter(x=x, y=st_agg, name=\"Train Time (Agg.)\"),\n",
    "    ],\n",
    "    rows=[1, 1, 1, 1, 1, 1, 1, 1, 2, 2],\n",
    "    cols=[1, 1, 1, 1, 2, 2, 2, 2, 1, 1],\n",
    ")\n",
    "\n",
    "fig = (\n",
    "    fig.update_xaxes(type=\"log\", title=\"Sample Size (log10 scale)\")\n",
    "    .update_yaxes(title=\"Mean\", row=1, col=1)\n",
    "    .update_yaxes(title=\"Std.\", row=1, col=2)\n",
    "    .update_yaxes(title=\"Seconds\", row=2, col=1)\n",
    "    .update_layout(title=\"Normal Model vs Aggregated Normal Model\")\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "py.plot(fig, filename=\"medium-scaling-byi-normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ea56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_normal[pdf_normal[\"size\"] == 1_000].rename(columns={\"x\": \"value\"}).assign(\n",
    "    bins=lambda x: pd.cut(x[\"value\"], bins=10), freq=1\n",
    ").groupby(\"bins\").agg({\"value\": \"mean\", \"freq\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01208e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5309a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=pdf_normal[pdf_normal[\"size\"] == 1_000], x=\"x\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11360d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
